# author: Ruofei Du
# This script builds the website by parsing the markdown text files and json files in data/
# This script also includes common files such as header and footer, and embed them into the final HTML
from xml.etree import ElementTree as ET
from scripts.types import *
import re, json
import markdown

re_markdown = re.compile("<!--\s*include\s*:\s*data\/(.+)\.txt\s*?-->")
re_html = re.compile("<!--\s*include\s*:\s*(.+)\.html\s*?-->")


def remove_comments(html):
    return re.sub("(<!--.*?-->)", "", html, flags=re.DOTALL)


def remove_blank_lines(html):
    return re.sub("\n\s*\n", "\n", html, flags=re.DOTALL)


def read_str(file_name):
    with open(file_name, 'r') as f:
        s = ''.join(f.readlines())
    return s


def read_html(file_name):
    s = read_str(file_name + '.html')
    while re_html.search(s):
        key = re_html.search(s).groups()[0]
        print("%s\t<=\t%s.html" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*" + key + "\.html\s*-->", html[key], s, flags=re.DOTALL)
    return s


def read_content(file_name):
    s = read_html(file_name + '.content')
    while re_markdown.search(s):
        key = re_markdown.search(s).groups()[0]
        print("%s\t<=\t%s.txt" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*data\/" + key + "\.txt\s*-->", md[key], s, flags=re.DOTALL)
    while re_html.search(s):
        key = re_html.search(s).groups()[0]
        print("%s\t<=\t%s.html" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*" + key + "\.html\s*-->", html[key], s, flags=re.DOTALL)

    s = remove_comments(s)
    s = remove_blank_lines(s)
    return s


def build(file_name):
    print("---")
    s = read_content(file_name)
    # Build to separate folders
    # out_file = "%s.html" % file_name if file_name == 'index' else "%s/index.html" % file_name
    # Build to the root
    out_file = "%s.html" % file_name
    with open(out_file, 'w') as f:
        f.write('<!-- Automatically generated by build.py from MarkDown files -->\n')
        f.write('<!-- Augmentarium | UMIACS | University of Maryland, College Park -->\n')
        f.write(s)


def read_markdown(file_name):
    s = read_str('data/' + file_name + '.txt')
    s = markdown.markdown(s)
    return s


def read_data(file_name):
    return json.load(open('data/' + file_name + '.json'))


def write_bib(b):
    filename = 'bib/' + b['bib'] + '.bib'
    if 'http' in filename:
        return
    print(filename)
    with open(filename, 'w') as f:
        f.write('@%s{%s,<br/>\n' % (b['type'], b['bibname']))
        f.write('    title = "%s",<br/>\n' % b['title'])
        f.write('    author = "%s",<br/>\n' % b['author'])
        f.write('    %s = "%s",<br/>\n' % ('journal' if b['type'] == 'article' else 'booktitle', b['booktitle']))
        f.write('    year = "%s",<br/>\n' % b['year'])
        f.write('    volume = "%s",<br/>\n' % b['volume'])
        f.write('    pages = "%s"<br/>\n' % b['pages'])
        f.write('}<br/>\n')


def write_data_to_markdown(file_name):
    line_media = '* %s, [%s](%s), %s%s %s, %s.\n'
    line_students = '<div class="2u 12u$(medium) center"><span class="image fit">' \
                    '<a href="%s" target="_blank"><img src="photos/%s" alt="%s" class="face"/></a></span>' \
                    '<h4 class="center"><a href="%s" target="_blank" class="name">%s</a></h4></div>\n'
    # (m['image'], m['title'], m['url'], m['title'], m['author'], m['booktitle'], m['keywords'], m['url'], m['video'], m['code'], m['slides'], m['apa'], m['bib']  )
    line_papers = '<div class="3u 12u$(medium)"><span class="image fit"><img src="teaser/%s" alt="%s" /></span></div>' \
                  '<div class="9u 12u$(medium)"><h4><a href="%s">%s</a></h4>' \
                  '<p>' \
                  '<span class="authors">%s<span>' \
                  '<br/>' \
                  '<span class="booktitle">%s</span>' \
                  '<br/>' \
                  '<span class="keywords">%s</span>' \
                  '<br/>' \
                  '<span class="download">Download: <a href="%s" target="_blank">[pdf]</a> %s%s%s | ' \
                  'Export <a href="%s" class="bibtex">[Citation]</a> <a href="%s" class="bibtex">[BibTeX]</a></span>' \
                  '</p></div>'

    CATEGORY = '### %s\n'
    YEAR = '### %s\n'
    NEW_ROW = '<div class="row">\n'
    ROW_END = '</div>\n'

    with open("data/%s.txt" % file_name, 'w') as f:
        f.write('[comment]: <> (This markdown file is generated from %s.json by build.py)\n' % file_name)
        if file_name == 'media':
            for m in reversed(data['media']):
                f.write(line_media % (
                    m['publisher'], m['title'], m['url'], '(Video) ' if m['video'] else '', m['month'], m['day'],
                    m['year']))
        elif file_name == 'students':
            categories = []
            for m in data['students']:
                if m['category'] not in categories:
                    categories.append(m['category'])
            for c in categories:
                f.write(CATEGORY % c)
                count = 0
                f.write(NEW_ROW)
                for m in data['students']:
                    if m['category'] == c and m['visible']:
                        if count and count % 5 == 0:
                            f.write(ROW_END)
                            f.write(NEW_ROW)
                        f.write(line_students % (m['url'], m['photo'], m['name'] + "'s photo", m['url'], m['name']))
                        count += 1
                f.write(ROW_END)
        elif file_name == 'papers':
            years = []
            for m in data['papers']:
                if m['year'] not in years:
                    years.append(m['year'])
                if not m['bib']:
                    m['bib'] = m['bibname']
                write_bib(m)
                m['url'] = 'papers/' + m['url'] if not 'http' in m['url'] else m['url']
                m['bib'] = 'bib/' + m['bib'] + '.bib'
                m['apa'] = 'bib/' + m['bib'] + '.apa'
                m['video'] = '| <a href="%s" target="blank">[video]</a>' % m['video'] if m['video'] else ''
                m['code'] = '| <a href="%s" target="blank">[code]</a>' % m['code'] if m['code'] else ''
                m['slides'] = '| <a href="%s" target="blank">[slides]</a>' % m['slides'] if m['slides'] else ''
            for y in sorted(years, reverse=True):
                f.write(YEAR % y)
                count = 0
                for m in data['papers']:
                    if m['year'] == y and m['visible']:
                        f.write(NEW_ROW)
                        f.write(line_papers % (
                            m['image'], m['title'], m['url'], m['title'], m['author'], m['booktitle'], m['keywords'],
                            m['url'], m['video'], m['code'], m['slides'], m['apa'], m['bib']))
                        f.write(ROW_END)
                        count += 1


html_files = ['header', 'footer', 'contact', 'menu', 'sidebar', 'banner']
data_files = ['media', 'students', 'papers']
md_files = ['bio', 'media', 'activities', 'students', 'ungrads', 'papers']
build_files = ['index', 'media', 'activities', 'students', 'publications']

html, md, data = {}, {}, {}

# First, parse Json Data and write to Markdown files
for f in data_files:
    data[f] = read_data(f)
for m in data['media']:
    m['title'] = smart_title(m['title'])
for f in data_files:
    write_data_to_markdown(f)

# Next, read and parse HTML and MARKDOWN file for including
for f in html_files:
    html[f] = read_html(f)
for f in md_files:
    md[f] = read_markdown(f)

# Finally, generate combined files
for f in build_files:
    build(f)
